{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Qpb5BHwlsFJx_6ex3675fFXcCzNA8b12",
      "authorship_tag": "ABX9TyOmJ9nKTxe2EEa6NousTFur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krcpr007/Watermarking-Deep-Neural-Networks/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "des3oI4mrzQo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.regularizers import Regularizer\n",
        "import tensorflow.keras.backend as K\n",
        "from scipy.special import comb\n",
        "import tensorflow as tf\n",
        "def compute_mismatch_threshold(C=10, Kp=50, p=0.05):\n",
        "    prob_sum = 0\n",
        "    p_err = 1 - 1.0 / C\n",
        "    for i in range(Kp):\n",
        "        cur_prob = comb(Kp, i, exact=False) * np.power(p_err, i) * np.power(1 - p_err, Kp - i)\n",
        "        prob_sum = prob_sum + cur_prob\n",
        "        if prob_sum > p:\n",
        "            theta = i\n",
        "            break\n",
        "\n",
        "    return theta\n",
        "\n",
        "def key_generation(x_train, y_train, marked_model, desired_key_len, num_classes=10, embed_epoch=20, modulation_strength=60000):\n",
        "    key_len = np.dot(40, desired_key_len)\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    x_test = x_test.reshape(10000, 784)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)  # Updated to tf.keras.utils\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)    # Updated to tf.keras.utils\n",
        "    key_gen_flag = 1\n",
        "    while key_gen_flag:\n",
        "        np.random.seed()\n",
        "        x_retrain_rand = np.random.randint(256, size=(key_len, 784))\n",
        "        x_retrain_rand = x_retrain_rand / 255.0\n",
        "        np.random.seed()\n",
        "        y_retrain_rand_vec = np.random.randint(10, size=(key_len, 1))\n",
        "        y_retrain_rand = tf.keras.utils.to_categorical(y_retrain_rand_vec, num_classes)  # Updated to tf.keras.utils\n",
        "        x_train_subset = x_train[0:modulation_strength, :]\n",
        "        y_train_subset = y_train[0:modulation_strength, :]\n",
        "        x_retrain = np.vstack((x_train_subset, x_retrain_rand))\n",
        "        y_retrain = np.vstack((y_train_subset, y_retrain_rand))\n",
        "        unmarked_score = marked_model.evaluate(x_test, y_test, verbose=0)\n",
        "        prediction_random_key = marked_model.predict(x_retrain_rand, batch_size=batch_size)\n",
        "        preds = np.argmax(prediction_random_key, axis=1)\n",
        "        preds = np.reshape(preds, (key_len, 1))\n",
        "        mismatched_result = (preds != y_retrain_rand_vec) * 1\n",
        "        random_unmarkMismatched_idx = np.argwhere(mismatched_result)\n",
        "        random_unmarkMismatched_idx = random_unmarkMismatched_idx[:, 0]\n",
        "        history = marked_model.fit(x_retrain, y_retrain, batch_size=batch_size, epochs=embed_epoch, shuffle=True, verbose=1, validation_data=(x_test, y_test))\n",
        "        score = marked_model.evaluate(x_test, y_test, verbose=0)\n",
        "        score = marked_model.evaluate(x_retrain_rand, y_retrain_rand, verbose=0)\n",
        "        Perr_marked = 1 - score[1]\n",
        "        mark_NN_err = int(Perr_marked * key_len)\n",
        "        prediction_random_key = marked_model.predict(x_retrain_rand, batch_size=batch_size)\n",
        "        preds = np.argmax(prediction_random_key, axis=1)\n",
        "        preds = np.reshape(preds, (key_len, 1))\n",
        "        matched_result = (preds == y_retrain_rand_vec) * 1\n",
        "        matched_result = np.reshape(matched_result, (matched_result.shape[0], 1))\n",
        "        random_MarkMatched_idx = np.argwhere(matched_result)\n",
        "        random_MarkMatched_idx = random_MarkMatched_idx[:, 0]\n",
        "        selected_key_idx = np.intersect1d(random_MarkMatched_idx, random_unmarkMismatched_idx)\n",
        "        selected_keys = x_retrain_rand[np.array(selected_key_idx).astype(int), :]\n",
        "        selected_keys_labels = y_retrain_rand[np.array(selected_key_idx).astype(int)]\n",
        "        usable_key_len = selected_keys.shape[0]\n",
        "        print('Usable key len is: ', usable_key_len)\n",
        "        if usable_key_len < desired_key_len:\n",
        "            key_gen_flag = 1\n",
        "            print(' Desired key length is {}, Longer key needed, skip this test. '.format(desired_key_len))\n",
        "        else:\n",
        "            key_gen_flag = 0\n",
        "            selected_keys = selected_keys[0:desired_key_len, :]\n",
        "            selected_keys_labels = selected_keys_labels[0:desired_key_len]\n",
        "            np.save('/content/drive/MyDrive/Colab Notebooks/keyRandomImage' + '_keyLength' + str(desired_key_len) + '.npy', selected_keys)\n",
        "            np.savetxt('/content/drive/MyDrive/Colab Notebooks/keyRandomLabel' + '_keyLength' + str(desired_key_len) + '.txt', selected_keys_labels, fmt='%i', delimiter=',')\n",
        "            actual_key_len = selected_keys.shape[0]\n",
        "            marked_model.save_weights('/content/drive/MyDrive/Colab Notebooks/markedWeights' + '.h5')\n",
        "            print('WM key generation finished. Save watermarked model. ')\n",
        "            break\n",
        "\n",
        "    return (selected_keys, selected_keys_labels)\n",
        "\n",
        "def count_response_mismatch(Y_preds, Y_key):\n",
        "    num_mismatch = np.sum((Y_preds == Y_key) * 1)\n",
        "    return num_mismatch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "def create_model(num_classes=10):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary() #shows summery of model\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Jw5vuqQLsGQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, concatenate, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.regularizers import Regularizer\n",
        "import numpy as np\n",
        "\n",
        "def initial_conv(input):\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0, regularizer=None):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    if init.shape[channel_axis] != 16 * k:\n",
        "        init = Conv2D(16 * k, (1, 1), activation=\"linear\", padding=\"same\")(init)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding=\"same\")(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding=\"same\", kernel_regularizer=regularizer)(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = concatenate([init, x], axis=channel_axis)\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0, regularizer=None):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    if init.shape[channel_axis] != 32 * k:\n",
        "        init = Conv2D(32 * k, (1, 1), activation=\"linear\", padding=\"same\")(init)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding=\"same\")(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding=\"same\", kernel_regularizer=regularizer)(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = concatenate([init, x], axis=channel_axis)\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0, regularizer=None):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    if init.shape[channel_axis] != 64 * k:\n",
        "        init = Conv2D(64 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = concatenate([init, x], axis=channel_axis)\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1, wmark_regularizer=None, target_blk_num=1):\n",
        "    def get_regularizer(blk_num, idx):\n",
        "        if wmark_regularizer is not None and target_blk_num == blk_num and idx == 0:\n",
        "            print('target regularizer({}, {})'.format(blk_num, idx))\n",
        "            return wmark_regularizer\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    for i in range(N):\n",
        "        x = conv1_block(x, k, dropout, get_regularizer(1, i))\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2,2), padding='same')(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = conv2_block(x, k, dropout, get_regularizer(2, i))\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2,2), padding='same')(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = conv3_block(x, k, dropout, get_regularizer(3, i))\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = AveragePooling2D((8,8), padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    init = (32, 32, 3)\n",
        "\n",
        "    wrn_28_10 = create_wide_residual_network(init, nb_classes=100, N=4, k=10, dropout=0.25)\n",
        "\n",
        "    wrn_28_10.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n90Xv1qosfoK",
        "outputId": "bbc705d8-dd24-467e-ebff-bb436bd9a990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wide Residual Network-28-10 created.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 16)           64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 16)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 160)          23200     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 160)          640       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 32, 32, 160)          0         ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 160)          230560    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 160)          640       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 160)          2720      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 320)          0         ['conv2d_1[0][0]',            \n",
            "                                                                     'activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 160)          460960    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 160)          640       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 32, 32, 160)          0         ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 160)          230560    ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 160)          640       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 160)          51360     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 32, 32, 320)          0         ['conv2d_4[0][0]',            \n",
            " )                                                                   'activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 160)          460960    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 160)          640       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 32, 32, 160)          0         ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 160)          230560    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 160)          640       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 160)          51360     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 32, 32, 320)          0         ['conv2d_7[0][0]',            \n",
            " )                                                                   'activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 160)          460960    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 160)          640       ['conv2d_11[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32, 32, 160)          0         ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 160)          230560    ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 32, 32, 160)          640       ['conv2d_12[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 160)          51360     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 32, 32, 160)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 32, 32, 320)          0         ['conv2d_10[0][0]',           \n",
            " )                                                                   'activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 320)          0         ['concatenate_3[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 320)          921920    ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 320)          1280      ['conv2d_13[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 320)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 16, 16, 320)          0         ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 320)          921920    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 320)          1280      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 16, 16, 640)          0         ['max_pooling2d[0][0]',       \n",
            " )                                                                   'activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 320)          1843520   ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 320)          1280      ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 16, 16, 320)          0         ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 320)          921920    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 320)          1280      ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 320)          205120    ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 16, 16, 640)          0         ['conv2d_15[0][0]',           \n",
            " )                                                                   'activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 320)          1843520   ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 320)          1280      ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 16, 16, 320)          0         ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 320)          921920    ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 320)          1280      ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 320)          205120    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 16, 16, 640)          0         ['conv2d_18[0][0]',           \n",
            " )                                                                   'activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 320)          1843520   ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 320)          1280      ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 16, 16, 320)          0         ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 320)          921920    ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 16, 16, 320)          1280      ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 320)          205120    ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 16, 16, 320)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 16, 16, 640)          0         ['conv2d_21[0][0]',           \n",
            " )                                                                   'activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 640)            0         ['concatenate_7[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 8, 8, 640)            3687040   ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 8, 8, 640)            2560      ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 8, 8, 640)            0         ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 8, 8, 640)            3687040   ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 640)            2560      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 8, 8, 1280)           0         ['max_pooling2d_1[0][0]',     \n",
            " )                                                                   'activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 8, 8, 640)            7373440   ['concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 8, 8, 640)            2560      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 8, 8, 640)            0         ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 8, 8, 640)            3687040   ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 8, 8, 640)            2560      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 8, 8, 640)            819840    ['concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 8, 8, 1280)           0         ['conv2d_26[0][0]',           \n",
            " )                                                                   'activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 8, 8, 640)            7373440   ['concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 8, 8, 640)            2560      ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 8, 8, 640)            0         ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 8, 8, 640)            3687040   ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 8, 8, 640)            2560      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 8, 8, 640)            819840    ['concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 8, 8, 1280)           0         ['conv2d_29[0][0]',           \n",
            " e)                                                                  'activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 8, 8, 640)            7373440   ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 8, 8, 640)            2560      ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 8, 8, 640)            0         ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 8, 8, 640)            3687040   ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 8, 8, 640)            2560      ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 8, 8, 640)            819840    ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 8, 8, 640)            0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 8, 8, 1280)           0         ['conv2d_32[0][0]',           \n",
            " e)                                                                  'activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 1, 1, 1280)           0         ['concatenate_11[0][0]']      \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 1280)                 0         ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 100)                  128100    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 56420132 (215.23 MB)\n",
            "Trainable params: 56402180 (215.16 MB)\n",
            "Non-trainable params: 17952 (70.12 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.optimizers import SGD\n",
        "import keras\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    num_classes = 10\n",
        "    batch_size = 128\n",
        "\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    x_test = x_test.reshape(10000, 784)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    key_len = 20              ## desired WM key length\n",
        "    embed_lr = 0.0008\n",
        "    p_threshold = 0.0001\n",
        "    embed_epoch = 2\n",
        "\n",
        "    ## ---- Embed WM ------ ##\n",
        "    model = create_model()\n",
        "    model.load_weights('/content/drive/MyDrive/Colab Notebooks/markedWeights.h5')\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(learning_rate=embed_lr, momentum=0.9, decay=0.0, nesterov=True), metrics=['accuracy'])\n",
        "    X_key, Y_key = key_generation(x_train, y_train, model, key_len, num_classes, embed_epoch)\n",
        "\n",
        "\n",
        "    print(\"Detect WM\")\n",
        "    ## ----- Detect WM ------ ##\n",
        "    #marked_model = create_model()\n",
        "    #marked_model.load_weights('/content/drive/MyDrive/Colab Notebooks/markedWeights'+'.h5')\n",
        "    #marked_model.compile(loss='categorical_crossentropy',\n",
        "                #optimizer=SGD(learning_rate=embed_lr, momentum=0.9, decay=0.0, nesterov=True), metrics=['accuracy'])\n",
        "    #preds_onehot = marked_model.predict(X_key, batch_size=batch_size)\n",
        "    preds_onehot = model.predict(X_key, batch_size=batch_size)\n",
        "    Y_preds = np.reshape(np.argmax(preds_onehot, axis=1), (key_len, 1))\n",
        "    m = count_response_mismatch(Y_preds, Y_key)\n",
        "    theta = compute_mismatch_threshold(C=num_classes, Kp=key_len, p=p_threshold) # pk = 1/C, |K|: # trials\n",
        "\n",
        "    print('Probability threshold p is ', p_threshold)\n",
        "    print('Mismatch threshold is : ', theta)\n",
        "    print('Mismatch count of marked model on WM key set = ', m)\n",
        "    print(\"If the marked model is correctly authenticated by the owner: \", m < theta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAqGGcszswou",
        "outputId": "fd16462f-1c98-4d0c-8951-da1a55c83603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669706 (2.55 MB)\n",
            "Trainable params: 669706 (2.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Epoch 1/2\n",
            "475/475 [==============================] - 11s 22ms/step - loss: 0.0766 - accuracy: 0.9869 - val_loss: 0.2415 - val_accuracy: 0.9835\n",
            "Epoch 2/2\n",
            "475/475 [==============================] - 9s 19ms/step - loss: 0.0669 - accuracy: 0.9867 - val_loss: 0.2367 - val_accuracy: 0.9831\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Usable key len is:  45\n",
            "WM key generation finished. Save watermarked model. \n",
            "Detect WM\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Probability threshold p is  0.0001\n",
            "Mismatch threshold is :  12\n",
            "Mismatch count of marked model on WM key set =  10\n",
            "If the marked model is correctly authenticated by the owner:  True\n"
          ]
        }
      ]
    }
  ]
}